{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c257543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Read data from CSV and write to file in desired format\n",
    "with open('residues.dat', 'w') as file:\n",
    "    writer = csv.writer(file, delimiter='\\t')\n",
    "    writer.writerow([\"#AA\", \"Mass\", \"Charge\", \"Sigma\", \"Lambda\"])\n",
    "\n",
    "    with open('residues.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b7dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d082203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys,os,numpy as np\n",
    "import hoomd, hoomd.md as md\n",
    "import hoomd.deprecated as old\n",
    "#from hoomd\n",
    "import azplugins\n",
    "import gsd, gsd.hoomd, gsd.pygsd \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33f1ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hoomd\n",
    "import hoomd.md\n",
    "import azplugins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf3987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c182e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mdtraj as md\n",
    "from argparse import ArgumentParser\n",
    "from scipy.optimize import curve_fit\n",
    "from itertools import combinations\n",
    "from numpy import linalg\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy import constants\n",
    "sys.path.append('BLOCKING')\n",
    "# from main import BlockAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c51fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xy_spiral_array(n, delta=0, arc=.38, separation=.7):\n",
    "    \"\"\"\n",
    "    create points on an Archimedes' spiral\n",
    "    with `arc` giving the length of arc between two points\n",
    "    and `separation` giving the distance between consecutive\n",
    "    turnings\n",
    "    \"\"\"\n",
    "    def p2c(r, phi):\n",
    "        \"\"\"\n",
    "        polar to cartesian\n",
    "        \"\"\"\n",
    "        return (r * np.cos(phi), r * np.sin(phi))\n",
    "    r = arc\n",
    "    b = separation / (2 * np.pi)\n",
    "    phi = float(r) / b\n",
    "    coords = []\n",
    "    for i in range(n):\n",
    "        coords.append(list(p2c(r, phi))+[0])\n",
    "        phi += float(arc) / r\n",
    "        r = b * phi\n",
    "    return np.array(coords)+delta\n",
    "\n",
    "def genTop(residues,fasta,path,L):\n",
    "    N_res = len(fasta)\n",
    "    top = md.Topology()\n",
    "    chain = top.add_chain()\n",
    "    for resname in fasta:\n",
    "        residue = top.add_residue(residues.loc[resname,'three'], chain)\n",
    "        top.add_atom(residues.loc[resname,'three'], element=md.element.carbon, residue=residue)\n",
    "    for i in range(N_res-1):\n",
    "        top.add_bond(top.atom(i),top.atom(i+1))\n",
    "    pos = [[0,0,(i-N_res/2.)*.38] for i in range(N_res)]\n",
    "    t = md.Trajectory(np.array(pos).reshape(N_res,3), top, 0, [L,L,L], [90,90,90])\n",
    "    t.save_pdb(path+'/top.pdb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b70499e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#energy functions\n",
    "HALR = lambda r,s,l : 4*0.8368*l*((s/r)**12-(s/r)**6)\n",
    "HASR = lambda r,s,l : 4*0.8368*((s/r)**12-(s/r)**6)+0.8368*(1-l)\n",
    "HA = lambda r,s,l : np.where(r<2**(1/6)*s, HASR(r,s,l), HALR(r,s,l))\n",
    "HASP = lambda r,s,l,rc : np.where(r<rc, HA(r,s,l)-HA(rc,s,l), 0)\n",
    "\n",
    "#force functions\n",
    "LJ_F = lambda r,s,rvec : -6*4*0.8368*(2*s**12/r**14-s**6/r**8)*rvec\n",
    "HA_F = lambda r,s,l,rvec : np.where(r<2**(1/6)*s, LJ_F(r,s,rvec), l*LJ_F(r,s,rvec))\n",
    "HASP_F = lambda r,s,l,rvec,rc : np.where(r<rc, HA_F(r,s,l,rvec), 0)\n",
    "\n",
    "DH_F = lambda r,yukawa_eps,yukawa_kappa,rvec : -yukawa_eps*np.exp(-r*yukawa_kappa)*(1+r*yukawa_kappa)/r**3*rvec\n",
    "DHSP_F = lambda r,yukawa_eps,yukawa_kappa,rvec,rc : np.where(r<rc, DH_F(r,yukawa_eps,yukawa_kappa,rvec), 0)\n",
    "\n",
    "def calcEnergyMap(t,df,prot,rc):\n",
    "    indices = t.top.select_pairs('all','all')\n",
    "    mask = np.abs(indices[:,0]-indices[:,1])>1 #exclude >1, was used to exclude bonded pairs\n",
    "    indices = indices[mask]\n",
    "    dvec = md.compute_displacements(t,indices) #vector distances between pairs for each frame\n",
    "    d = linalg.norm(dvec,axis=2)\n",
    "    pairs = np.array(list(combinations(list(prot.seq),2)))\n",
    "    pairs = pairs[mask]\n",
    "    sigmas = 0.5*(df.loc[pairs[:,0]].sigmas.values+df.loc[pairs[:,1]].sigmas.values)\n",
    "    lambdas = 0.5*(df.loc[pairs[:,0]].lambdas.values+df.loc[pairs[:,1]].lambdas.values)\n",
    "    temp = 310\n",
    "    ionic = 0.15\n",
    "    RT = 8.3145*temp*1e-3\n",
    "    fepsw = lambda T : 5321/T+233.76-0.9297*T+0.1417*1e-2*T*T-0.8292*1e-6*T**3\n",
    "    epsw = fepsw(temp)\n",
    "    lB = 1.6021766**2/(4*np.pi*8.854188*epsw)*6.022*1000/RT\n",
    "    # Calculate the inverse of the Debye length\n",
    "    yukawa_kappa = np.sqrt(8*np.pi*lB*ionic*6.022/10)\n",
    "    qq = df.loc[pairs[:,0]].q.values*df.loc[pairs[:,1]].q.values\n",
    "    yukawa_eps = qq*lB*RT\n",
    "    emap = np.zeros(pairs.shape[0])\n",
    "    forces = np.zeros((t.n_frames,t.n_atoms,3))\n",
    "    for j,(r,rvec) in enumerate(zip(np.split(d,20,axis=0),np.split(dvec,20,axis=0))):\n",
    "        emap += np.nansum(HASP(r,sigmas[np.newaxis,:],lambdas[np.newaxis,:],rc),axis=0)\n",
    "        for i in range(t.n_atoms):\n",
    "            ndx_pairs = np.any(indices==i,axis=1)\n",
    "            forces[j*r.shape[0]:(j+1)*r.shape[0],i] = np.nansum(HASP_F(r[:,ndx_pairs,np.newaxis],sigmas[np.newaxis,ndx_pairs,np.newaxis],\n",
    "                            lambdas[np.newaxis,ndx_pairs,np.newaxis],rvec[:,ndx_pairs],rc),axis=1)\n",
    "            forces[j*r.shape[0]:(j+1)*r.shape[0],i] += np.nansum(DHSP_F(r[:,ndx_pairs,np.newaxis],\n",
    "                            yukawa_eps[np.newaxis,ndx_pairs,np.newaxis],yukawa_kappa,rvec[:,ndx_pairs],4),axis=1)\n",
    "    return indices, emap/d.shape[0], forces\n",
    "\n",
    "def calcRg(t,residues,seq):\n",
    "    fasta = list(seq.seq)\n",
    "    masses = residues.loc[fasta,'MW'].values\n",
    "    # calculate the center of mass\n",
    "    cm = np.sum(t.xyz*masses[np.newaxis,:,np.newaxis],axis=1)/masses.sum()\n",
    "    # calculate residue-cm distances\n",
    "    si = np.linalg.norm(t.xyz - cm[:,np.newaxis,:],axis=2)\n",
    "    # calculate rg\n",
    "    rgarray = np.sqrt(np.sum(si**2*masses,axis=1)/masses.sum())\n",
    "    return rgarray\n",
    "\n",
    "def error_ratio(v1,v2,e1,e2):\n",
    "    ratio = v1/v2\n",
    "    return ratio*np.sqrt((e1/v1)**2+(e2/v2)**2)\n",
    "\n",
    "def calcRgTensor(t,residues,seq,forces):\n",
    "    fasta = list(seq.seq)\n",
    "    masses = residues.loc[fasta,'MW'].values[np.newaxis,:,np.newaxis]\n",
    "\n",
    "    prefactor = constants.Boltzmann*310/constants.hbar**2\n",
    "    forces = forces/np.sqrt(masses/1e3/constants.Avogadro)\n",
    "    forces = forces.reshape(t.n_frames,-1)*1e3/constants.Avogadro*1e9\n",
    "    sigma = LedoitWolf().fit(forces).covariance_\n",
    "    eigenvalues = linalg.eigvalsh(sigma)\n",
    "    kT_over_hbar_omega = constants.Boltzmann*310*np.sqrt(prefactor/eigenvalues)\n",
    "    SPR = np.sum(np.log(kT_over_hbar_omega+1))/seq.nres_seg # R\n",
    "\n",
    "    # calculate the center of mass\n",
    "    cm = np.sum(t.xyz*masses,axis=1)/masses.sum()\n",
    "    # calculate residue-cm distances\n",
    "    si = t.xyz - cm[:,np.newaxis,:]\n",
    "    q = np.einsum('jim,jin->jmn', si*masses,si)/masses.sum()\n",
    "    trace_q = np.trace(q,axis1=1,axis2=2)\n",
    "    # calculate rg\n",
    "    rgarray = np.sqrt(trace_q)\n",
    "    # calculate traceless matrix\n",
    "    mean_trace = np.trace(q,axis1=1,axis2=2)/3\n",
    "    q_hat = q - mean_trace.reshape(-1,1,1)*np.identity(3).reshape(-1,3,3)\n",
    "    # calculate asphericity\n",
    "    Delta_array = 3/2*np.trace(q_hat**2,axis1=1,axis2=2)/(trace_q**2)\n",
    "    # calculate oblateness\n",
    "    S_array = 27*linalg.det(q_hat)/(trace_q**3)\n",
    "    # calculate ensemble averages\n",
    "    block_tr_q_hat_2 = BlockAnalysis(np.trace(q_hat**2,axis1=1,axis2=2), multi=1)\n",
    "    block_tr_q_hat_2.SEM()\n",
    "    block_tr_q_2 = BlockAnalysis(trace_q**2, multi=1)\n",
    "    block_tr_q_2.SEM()\n",
    "    block_det_q_hat = BlockAnalysis(linalg.det(q_hat), multi=1)\n",
    "    block_det_q_hat.SEM()\n",
    "    block_tr_q_3 = BlockAnalysis(trace_q**3, multi=1)\n",
    "    block_tr_q_3.SEM()\n",
    "    Delta = 3/2*block_tr_q_hat_2.av/block_tr_q_2.av\n",
    "    S = 27*block_det_q_hat.av/block_tr_q_3.av\n",
    "    Delta_err = 3/2*error_ratio(block_tr_q_hat_2.av,block_tr_q_2.av,block_tr_q_hat_2.sem,block_tr_q_2.sem)\n",
    "    S_err = 27*error_ratio(block_det_q_hat.av,block_tr_q_3.av,block_det_q_hat.sem,block_tr_q_3.sem)\n",
    "    return rgarray, Delta_array, S_array, Delta, S, Delta_err, S_err, SPR\n",
    "\n",
    "def calcRs(traj):\n",
    "    pairs = traj.top.select_pairs('all','all')\n",
    "    d = md.compute_distances(traj,pairs)\n",
    "    nres = traj.n_atoms\n",
    "    ij = np.arange(2,nres,1)\n",
    "    diff = [x[1]-x[0] for x in pairs]\n",
    "    dij = np.empty(0)\n",
    "    for i in ij:\n",
    "        dij = np.append(dij, np.sqrt((d[:,diff==i]**2).mean().mean()))\n",
    "    return ij,dij,np.mean(1/d,axis=1)\n",
    "\n",
    "def analyse(residues,path,seq):\n",
    "    top = md.Topology()\n",
    "    chain = top.add_chain()\n",
    "    if os.path.exists(path+'/traj.gsd'):\n",
    "        traj = md.load(path+'/traj.gsd')\n",
    "    else:\n",
    "        traj = md.load_xtc(path+'/traj.xtc',top=path+'/top.pdb')\n",
    "    N_res = traj.n_atoms\n",
    "    fasta = list(seq.seq)\n",
    "    #fixing the trajectory to the middle of the box\n",
    "    for resname in fasta:\n",
    "        residue = top.add_residue(residues.loc[resname,'three'],chain)\n",
    "        top.add_atom(residues.loc[resname,'three'], element=md.element.carbon, residue=residue)\n",
    "    for i in range(N_res-1):\n",
    "        top.add_bond(top.atom(i),top.atom(i+1))\n",
    "    traj.top = top\n",
    "    traj = traj.image_molecules(inplace=False, anchor_molecules=[set(traj.top.atoms)],make_whole=True)\n",
    "    print('Number of frames: {:d}'.format(traj.n_frames))\n",
    "    if os.path.exists(path+'/traj.gsd'):\n",
    "        traj[-1].save_pdb(path+'/top.pdb')\n",
    "        traj.save_xtc(path+'/traj.xtc')\n",
    "        os.remove(path+'/traj.gsd')\n",
    "    #skip first 10 frames\n",
    "    traj = traj[10:]\n",
    "    #energy maps\n",
    "    df_emap = pd.DataFrame(index=range(traj.n_atoms),columns=range(traj.n_atoms),dtype=float)\n",
    "    pairs, emap, forces = calcEnergyMap(traj,residues,seq,2.0)\n",
    "    for k,(i,j) in enumerate(pairs):\n",
    "        df_emap.loc[i,j] = emap[k]\n",
    "        df_emap.loc[j,i] = emap[k]\n",
    "    df_analysis = pd.DataFrame(index=['Rg','ete','rh','nu','R0','ete2_Rg2','Delta','S','SPR'],columns=['value','error'])\n",
    "    #rg\n",
    "    rgarray, Delta_array, S_array, Delta, S, Delta_err, S_err, SPR = calcRgTensor(traj,residues,seq,forces)\n",
    "    df_analysis.loc['Delta','value'] = Delta\n",
    "    df_analysis.loc['Delta','error'] = Delta_err\n",
    "    df_analysis.loc['S','value'] = S\n",
    "    df_analysis.loc['S','error'] = S_err\n",
    "    df_analysis.loc['SPR','value'] = SPR\n",
    "    df_analysis.loc['SPR','error'] = 0\n",
    "    np.save(path+'/rg.npy',rgarray)\n",
    "    np.save(path+'/Delta.npy',Delta_array)\n",
    "    np.save(path+'/S.npy',S_array)\n",
    "    block_rg = BlockAnalysis(rgarray, multi=1)\n",
    "    block_rg.SEM()\n",
    "    df_analysis.loc['Rg','value'] = block_rg.av\n",
    "    df_analysis.loc['Rg','error'] = block_rg.sem\n",
    "    #ete\n",
    "    ete = md.compute_distances(traj,atom_pairs=[[0,N_res-1]]).flatten()\n",
    "    np.save(path+'/ete.npy',ete)\n",
    "    block_ete = BlockAnalysis(ete, multi=1)\n",
    "    block_ete.SEM()\n",
    "    df_analysis.loc['ete','value'] = block_ete.av\n",
    "    df_analysis.loc['ete','error'] = block_ete.sem\n",
    "    block_ete2 = BlockAnalysis(np.power(ete,2), multi=1)\n",
    "    block_ete2.SEM()\n",
    "    block_rg2 = BlockAnalysis(np.power(rgarray,2), multi=1)\n",
    "    block_rg2.SEM()\n",
    "    ete2 = block_ete2.av\n",
    "    rg2 = block_rg2.av\n",
    "    ete2_e = block_ete2.sem\n",
    "    rg2_e = block_rg2.sem\n",
    "    df_analysis.loc['ete2_Rg2','value'] = ete2 / rg2\n",
    "    df_analysis.loc['ete2_Rg2','error'] = error_ratio(ete2,rg2,ete2_e,rg2_e)\n",
    "    #nonlinear scaling exponent\n",
    "    f = lambda x,R0,v : R0*np.power(x,v)\n",
    "    ij,dij,invrij = calcRs(traj)\n",
    "    block_invrij = BlockAnalysis(invrij, multi=1)\n",
    "    block_invrij.SEM()\n",
    "    df_analysis.loc['rh','value'] = 1/(1-1/N_res)/block_invrij.av\n",
    "    df_analysis.loc['rh','error'] = block_invrij.sem/(1-1/N_res)/block_invrij.av/block_invrij.av\n",
    "    np.save(path+'/rs.npy',dij)\n",
    "    popt, pcov = curve_fit(f,ij[ij>5],dij[ij>5],p0=[.4,.5])\n",
    "    df_analysis.loc['nu','value'] = popt[1]\n",
    "    df_analysis.loc['nu','error'] = pcov[1,1]**0.5\n",
    "    df_analysis.loc['R0','value'] = popt[0]\n",
    "    df_analysis.loc['R0','error'] = pcov[0,0]**0.5\n",
    "    return df_emap,df_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e642f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate(residues,sequences,seq_name,path):\n",
    "    seq = sequences #.loc[seq_name]\n",
    "    N_res = 21 #seq.nres_seg\n",
    "\n",
    "    if N_res > 500:\n",
    "        hoomd.context.initialize(\"--mode=gpu\");\n",
    "        L = 200\n",
    "    else:\n",
    "        hoomd.context.initialize(\"--mode=cpu\");\n",
    "        L = (N_res-1)*0.38+4\n",
    "\n",
    "    hoomd.option.set_notice_level(1)\n",
    "    hoomd.util.quiet_status()\n",
    "\n",
    "    lj_eps = 4.184*.2\n",
    "    temp = 310\n",
    "    ionic_strength = 0.15 # M\n",
    "    RT = 8.3145*temp*1e-3\n",
    "\n",
    "    yukawa_kappa, yukawa_eps, types, pairs, fasta, residues = genParams(residues,seq,temp,ionic_strength)\n",
    "    print(genParams(residues,seq,temp,ionic_strength))\n",
    "\n",
    "    sigmamap = pd.DataFrame((residues.sigmas.values+residues.sigmas.values.reshape(-1,1))/2,\n",
    "                            index=residues.sigmas.index,columns=residues.sigmas.index)\n",
    "    lambdamap = pd.DataFrame((residues.lambdas.values+residues.lambdas.values.reshape(-1,1))/2,\n",
    "                            index=residues.lambdas.index,columns=residues.lambdas.index)\n",
    "\n",
    "    N_save = 7000 if N_res < 150 else int(np.ceil(3e-4*N_res**2)*1000)\n",
    "    N_steps = 1010*N_save\n",
    "\n",
    "    genTop(residues,fasta,path,L)\n",
    "\n",
    "    snapshot = hoomd.data.make_snapshot(N=N_res,\n",
    "                                box=hoomd.data.boxdim(Lx=L, Ly=L, Lz=L),\n",
    "                                particle_types=types,\n",
    "                                bond_types=['polymer']);\n",
    "\n",
    "    snapshot.bonds.resize(N_res-1);\n",
    "\n",
    "    if N_res > 500:\n",
    "        snapshot.particles.position[:] = xy_spiral_array(N_res)\n",
    "    else:\n",
    "        snapshot.particles.position[:] = [[0,0,(i-N_res/2.)*.38] for i in range(N_res)]\n",
    "    snapshot.particles.typeid[:] = [types.index(a) for a in fasta]\n",
    "    snapshot.particles.mass[:] = [residues.loc[a].MW for a in fasta]\n",
    "\n",
    "    snapshot.bonds.group[:] = [[i,i+1] for i in range(N_res-1)];\n",
    "    snapshot.bonds.typeid[:] = [0] * (N_res-1)\n",
    "\n",
    "    hoomd.init.read_snapshot(snapshot);\n",
    "\n",
    "    hb = hoomd.md.bond.harmonic();\n",
    "    hb.bond_coeff.set('polymer', k=8033.0, r0=0.38);\n",
    "\n",
    "    nl = hoomd.md.nlist.cell();\n",
    "\n",
    "    ah = azplugins.pair.ashbaugh(r_cut=2.0, nlist=nl)\n",
    "    yukawa = hoomd.md.pair.yukawa(r_cut=4.0, nlist=nl)\n",
    "    for a,b in pairs:\n",
    "        ah.pair_coeff.set(a, b, lam=lambdamap.loc[a,b], epsilon=lj_eps, sigma=sigmamap.loc[a,b], r_cut=2.0)\n",
    "        yukawa.pair_coeff.set(a, b, epsilon=yukawa_eps.loc[a,b], kappa=yukawa_kappa, r_cut=4.)\n",
    "\n",
    "    ah.set_params(mode='shift')\n",
    "    yukawa.set_params(mode='shift')\n",
    "    nl.reset_exclusions(exclusions = ['bond'])\n",
    "\n",
    "    integrator_mode = hoomd.md.integrate.mode_standard(dt=0.005);\n",
    "    integrator = hoomd.md.integrate.langevin(group=hoomd.group.all(),kT=RT,seed=np.random.randint(100));\n",
    "\n",
    "    for a in types:\n",
    "        integrator.set_gamma(a, residues.loc[a].MW/100)\n",
    "\n",
    "    hoomd.run(10000)\n",
    "\n",
    "    integrator.disable()\n",
    "\n",
    "    integrator_mode = hoomd.md.integrate.mode_standard(dt=0.01);\n",
    "    integrator = hoomd.md.integrate.langevin(group=hoomd.group.all(),kT=RT,seed=np.random.randint(100));\n",
    "\n",
    "    for a in types:\n",
    "        integrator.set_gamma(a, residues.loc[a].MW/100)\n",
    "\n",
    "    hoomd.dump.gsd(filename=path+'/traj.gsd', period=N_save, group=hoomd.group.all(), overwrite=True);\n",
    "\n",
    "    hoomd.run(N_steps)\n",
    "\n",
    "    hoomd.dump.gsd(filename=path+'/restart.gsd', group=hoomd.group.all(), truncate=True, period=None, phase=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8b38714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b70eb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def genParams(r,seq,temp,ionic):\n",
    "    RT = 8.3145*temp*1e-3\n",
    "    pH = 7.4\n",
    "    fepsw = lambda T : 5321/T+233.76-0.9297*T+0.1417*1e-2*T*T-0.8292*1e-6*T**3\n",
    "    epsw = fepsw(temp)\n",
    "    lB = 1.6021766**2/(4*np.pi*8.854188*epsw)*6.022*1000/RT\n",
    "    # Calculate the inverse of the Debye length\n",
    "    yukawa_kappa = np.sqrt(8*np.pi*lB*ionic*6.022/10)\n",
    "    fasta = list(seq.seq)\n",
    "    # Set the charge on HIS based on the pH of the protein solution? Not needed if pH=7.4\n",
    "    # r.loc['H','q'] = 1. / ( 1 + 10**(pH-6) )\n",
    "    if seq['first'] == 1:\n",
    "        r.loc['X'] = r.loc[fasta[0]]\n",
    "        r.loc['X','q'] = r.loc[fasta[0],'q'] + 1.\n",
    "        r.loc['X','MW'] = r.loc[fasta[0],'MW'] + 2.\n",
    "        fasta[0] = 'X'\n",
    "    if seq['last'] == seq.nres_unip:\n",
    "        r.loc['Z'] = r.loc[fasta[-1]]\n",
    "        r.loc['Z','q'] = r.loc[fasta[-1],'q'] - 1.\n",
    "        r.loc['Z','MW'] = r.loc[fasta[-1],'MW'] + 16.\n",
    "        fasta[-1] = 'Z'\n",
    "    # Calculate the prefactor for the Yukawa potential\n",
    "    qq = pd.DataFrame(r.q.values*r.q.values.reshape(-1,1),index=r.q.index,columns=r.q.index)\n",
    "    yukawa_eps = qq*lB*RT\n",
    "    types = list(np.unique(fasta))\n",
    "    pairs = np.array(list(itertools.combinations_with_replacement(types,2)))\n",
    "    return yukawa_kappa, yukawa_eps, types, pairs, fasta, r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68a0c771",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'seq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3325217/1955197622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ctd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_emap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_analysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/analysis.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3325217/3863463825.py\u001b[0m in \u001b[0;36msimulate\u001b[0;34m(residues, sequences, seq_name, path)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mRT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8.3145\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0myukawa_kappa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myukawa_eps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfasta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mionic_strength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mionic_strength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3325217/3963254139.py\u001b[0m in \u001b[0;36mgenParams\u001b[0;34m(r, seq, temp, ionic)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Calculate the inverse of the Debye length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0myukawa_kappa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlB\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mionic\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6.022\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mfasta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Set the charge on HIS based on the pH of the protein solution? Not needed if pH=7.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# r.loc['H','q'] = 1. / ( 1 + 10**(pH-6) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'seq'"
     ]
    }
   ],
   "source": [
    "\n",
    "residues = pd.read_csv('residues.csv').set_index('one',drop=False)\n",
    "\n",
    "t0 = time.time()\n",
    "simulate(residues,sequences,'ctd','./')\n",
    "df_emap,df_analysis = analyse(residues,args.path,sequences.loc[args.seq_name])\n",
    "df_analysis.to_csv(args.path+'/analysis.csv')\n",
    "df_emap.to_csv(args.path+'/emap.csv')\n",
    "print('Timing sim and analysis {:.3f}'.format((time.time()-t0)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a71400ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3325217/2970968946.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mionic_strength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'seq' is not defined"
     ]
    }
   ],
   "source": [
    "genParams(residues,seq,temp,ionic_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757fa750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8bf2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5d5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05707bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ee80e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARG 156.19 1 0.6559999999999999 0.7307624767517166\n",
      "ASP 115.09 -1 0.5579999999999999 0.0416040480605567\n",
      "ASN 114.1 0 0.568 0.4255859009787713\n",
      "GLU 129.11 -1 0.5920000000000001 0.0006935460962935\n",
      "LYS 128.17 1 0.636 0.1790211738990582\n",
      "HIS 137.14 0 0.608 0.4663667290557992\n",
      "GLN 128.13 0 0.602 0.3934318551056041\n",
      "SER 87.08 0 0.518 0.4625416811611541\n",
      "CYS 103.14 0 0.5479999999999999 0.5615435099141777\n",
      "GLY 57.05 0 0.45 0.7058843733666401\n",
      "THR 101.11 0 0.562 0.3713162976273964\n",
      "ALA 71.07 0 0.504 0.2743297969040348\n",
      "MET 131.2 0 0.618 0.5308481134337497\n",
      "TYR 163.18 0 0.6459999999999999 0.9774611449343455\n",
      "VAL 99.13 0 0.5860000000000001 0.2083769608174481\n",
      "TRP 186.22 0 0.6779999999999999 0.9893764740371644\n",
      "LEU 113.16 0 0.618 0.6440005007782226\n",
      "ILE 113.16 0 0.618 0.5423623610671892\n",
      "PRO 97.12 0 0.5559999999999999 0.3593126576364644\n",
      "PHE 147.18 0 0.636 0.8672358982062975\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = \"residues.dat\"\n",
    "\n",
    "# Open the file for reading\n",
    "with open(file_path, 'r') as file:\n",
    "    # Iterate over each line in the file\n",
    "    for line in file:\n",
    "        # Split the line by whitespace\n",
    "        columns = line.split()\n",
    "        # Extract columns 1, 2, 3, 4, and 5\n",
    "        col_2 = columns[1]\n",
    "        col_3 = columns[2]\n",
    "        col_4 = columns[3]\n",
    "        col_5 = columns[4]\n",
    "        col_6 = columns[5]\n",
    "\n",
    "        # Print or process the extracted columns as needed\n",
    "        print( col_2, col_3,col_6,col_5, col_4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0f02638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "input_file_path = \"residues.dat\"\n",
    "output_file_path = \"new_residues.dat\"\n",
    "\n",
    "# Open the input file for reading and the output file for writing\n",
    "with open(input_file_path, 'r') as input_file, open(output_file_path, 'w') as output_file:\n",
    "    # Iterate over each line in the input file\n",
    "    for line in input_file:\n",
    "        # Split the line by whitespace\n",
    "        columns = line.split()\n",
    "        # Extract columns 2, 3, 6, 5, and 4 (reordered)\n",
    "        col_2 = columns[1]\n",
    "        col_3 = columns[2]\n",
    "        col_4 = columns[3]\n",
    "        col_5 = float(columns[4]) * 10  # Multiply col_5 by 10\n",
    "        col_6 = columns[5]\n",
    "        # Round col_5 to three significant figures\n",
    "        col_5_rounded = \"{:.3g}\".format(col_5)\n",
    "        # Write the reordered and modified columns to the output file\n",
    "        output_file.write(f\"{col_2} {col_3} {col_6} {col_5_rounded} {col_4}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4880a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9dad33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#AA', 'Mass', 'Charge', 'Sigma', 'Lambda']\n",
      "['ALA', '71.08', '0.00', '5.040', '0.730']\n",
      "['ARG', '156.20', '1.00', '6.560', '0.000']\n",
      "['ASN', '114.10', '0.00', '5.680', '0.432']\n",
      "['ASP', '115.10', '-1.00', '5.580', '0.378']\n",
      "['CYS', '103.10', '0.00', '5.480', '0.595']\n",
      "['GLN', '128.10', '0.00', '6.020', '0.514']\n",
      "['GLU', '129.10', '-1.00', '5.920', '0.459']\n",
      "['GLY', '57.05', '0.00', '4.500', '0.649']\n",
      "['HIS', '137.10', '0.50', '6.080', '0.514']\n",
      "['ILE', '113.20', '0.00', '6.180', '0.973']\n",
      "['LEU', '113.20', '0.00', '6.180', '0.973']\n",
      "['LYS', '128.20', '1.00', '6.360', '0.514']\n",
      "['MET', '131.20', '0.00', '6.180', '0.838']\n",
      "['PHE', '147.20', '0.00', '6.360', '1.000']\n",
      "['PRO', '97.12', '0.00', '5.560', '1.000']\n",
      "['SER', '87.08', '0.00', '5.180', '0.595']\n",
      "['THR', '101.10', '0.00', '5.620', '0.676']\n",
      "['TRP', '186.20', '0.00', '6.780', '0.946']\n",
      "['TYR', '163.20', '0.00', '6.460', '0.865']\n",
      "['VAL', '99.07', '0.00', '5.860', '0.892']\n",
      "['SEP', '165.03', '-2.00', '6.36', '0.162']\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = \"stats_module.dat\"\n",
    "\n",
    "# Open the file for reading\n",
    "with open(file_path, 'r') as file:\n",
    "    # Iterate over each line in the file\n",
    "    for line in file:\n",
    "        # Split the line by whitespace\n",
    "        columns = line.split()\n",
    "        \n",
    "        print( columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa881d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
